{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ex1_solutions.ipynb","provenance":[],"collapsed_sections":["vxrhhR3pwCEd","HTBtN8ox22Qz","FMH-rgnz0G5N"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Αναγνώριση Προτύπων - Μηχανική Μάθηση - Εργασία 1\n","## Νικόλαος Μασούρας sdi1800112"],"metadata":{"id":"zhrXXrrvvhVU"}},{"cell_type":"markdown","source":["# Ερώτημα 1: Πράξεις με Διανύσματα και Πίνακες"],"metadata":{"id":"vxrhhR3pwCEd"}},{"cell_type":"code","source":["\n","import numpy as np\n","\n","np.random.seed(112)\n","\n","X = np.random.randint(0,5,size=(3,4))\n","Y = np.random.randint(0,5,size=(4,3))\n","a = np.random.randint(0,5,size=(4,1))\n","b = np.random.randint(0,5,size=(4,1))\n","print(\"random arrays\")\n","print(\"X =\",X)\n","print(\"Y =\",Y)\n","\n","print(\"random vectors\")\n","print(\"a =\",a)\n","print(\"b =\",b)\n","c = np.transpose(a)\n","#1.1 inner a,b\n","print(\"inner a,b = \",int(c.dot(b)))\n","#1.2 calc Xa\n","print(\"Xa = \",X.dot(a))\n","#1.3 calc XY\n","print(\"XY = \",X.dot(Y))\n","#1.4 I2-norm of a\n","print(\"I2-norm of a = \",np.linalg.norm(a))"],"metadata":{"id":"fYpKK1xUwsF7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648716228786,"user_tz":-180,"elapsed":285,"user":{"displayName":"Nick sour","userId":"02771206742206724666"}},"outputId":"0e035254-8ac9-4810-82cd-d909997d9103"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["random arrays\n","X = [[4 3 0 2]\n"," [1 4 4 0]\n"," [4 1 2 0]]\n","Y = [[4 0 0]\n"," [3 3 4]\n"," [1 0 3]\n"," [2 1 2]]\n","random vectors\n","a = [[2]\n"," [2]\n"," [4]\n"," [0]]\n","b = [[2]\n"," [0]\n"," [0]\n"," [0]]\n","inner a,b =  4\n","Xa =  [[14]\n"," [26]\n"," [18]]\n","XY =  [[29 11 16]\n"," [20 12 28]\n"," [21  3 10]]\n","I2-norm of a =  4.898979485566356\n"]}]},{"cell_type":"markdown","source":["##Υπολογισμός με το χέρι\n","$ X = \\left[\\begin{array}{rrrr}\n","       4 & 3 & 0 & 2\\\\\n","       1 & 4 & 4 & 0\\\\\n","       4 & 1 & 2 & 0\\\\\n","       \\end{array}\\right],\n","  Y = \\left[\\begin{array}{rrr}\n","      4 & 0 & 0\\\\\n","      3 & 3 & 4\\\\\n","      1 & 0 & 3\\\\\n","      2 & 1 & 2\\\\\n","      \\end{array}\\right],\n","  a = \\left[\\begin{array}{r}\n","      2 \\\\ 2 \\\\ 4 \\\\ 0\n","      \\end{array}\\right],\n","  b = \\left[\\begin{array}{r}\n","      2 \\\\ 0 \\\\ 0 \\\\ 0\n","      \\end{array}\\right]\n","$\n","\n","**1.1**\n","\n","$\n","   <a,b> = a^Tb \n","        = \\left[\\begin{array}{rrrr}\n","          2 & 2 & 4 & 0\n","          \\end{array}\\right]\n","          \\left[\\begin{array}{r}\n","          2 \\\\ 0 \\\\ 0 \\\\ 0\n","          \\end{array}\\right]\n","        = 2*2 + 2*0 + 4*0 + 0*0 = 4\\\\\n","$\n","\n","\n","**1.2**\n","\n","$\n","   Xa = \\left[\\begin{array}{rrrr}\n","       4 & 3 & 0 & 2\\\\\n","       1 & 4 & 4 & 0\\\\\n","       4 & 1 & 2 & 0\\\\\n","       \\end{array}\\right]\n","       \\left[\\begin{array}{r}\n","          2 \\\\ 2 \\\\ 4 \\\\ 0\n","        \\end{array}\\right]\n","      = \\left[\\begin{array}{r}\n","          4*2 + 3*2 + 0*4 + 2*0 \\\\\n","          1*2 + 4*2 + 4*4 + 0*0 \\\\\n","          4*2 + 1*2 + 2*4 + 0*0 \\\\\n","        \\end{array}\\right]\n","      =\\left[\\begin{array}{r}\n","        14 \\\\\n","        26 \\\\\n","        18 \\\\\n","        \\end{array}\\right]\n","        \\\\\n","$\n","\n","**1.3**\n","\n","$\n","   XY = \\left[\\begin{array}{rrrr}\n","       4 & 3 & 0 & 2\\\\\n","       1 & 4 & 4 & 0\\\\\n","       4 & 1 & 2 & 0\\\\\n","       \\end{array}\\right]\n","       \\left[\\begin{array}{rrr}\n","        4 & 0 & 0\\\\\n","        3 & 3 & 4\\\\\n","        1 & 0 & 3\\\\\n","        2 & 1 & 2\\\\\n","        \\end{array}\\right]\n","      = \\left[\\begin{array}{rrr}\n","        4*4 + 3*3 + 0*1 + 2*2 & 4*0 + 3*3 + 0*0 + 2*1 & 4*0 + 3*4 + 0*3 + 2*2 \\\\\n","        1*4 + 4*3 + 4*1 + 0*2 & 1*0 + 4*3 + 4*0 + 0*1 & 1*0 + 4*4 + 4*3 + 0*2 \\\\\n","        4*4 + 1*3 + 2*1 + 0*2 & 4*0 + 1*3 + 2*0 + 0*1 & 4*0 + 1*4 + 2*3 + 0*2 \\\\\n","        \\end{array}\\right]\n","      = \\left[\\begin{array}{rrr}\n","        29 & 11 & 16 \\\\\n","        20 & 12 & 28 \\\\\n","        21 & 3  & 10 \\\\ \n","        \\end{array}\\right]\n","        \\\\\n","$\n","\n","\n","**1.4**\n","\n","$ \n","\\lVert a \\rVert_2 = \\sqrt{2^2 + 2^2 + 4^2 + 0} = \\sqrt{4 + 4 + 16}= \\sqrt{24} \n","    = 2\\sqrt{6} \n","$"],"metadata":{"id":"5HXiN3ESLc4k"}},{"cell_type":"markdown","source":["# Ερώτημα 2: Υπολογισμός παραγώγων"],"metadata":{"id":"HTBtN8ox22Qz"}},{"cell_type":"markdown","source":["## 2.1\n","$ f(x) = x^TAx + b^Tx,\n","  A = A^T dxd, b \\epsilon ℝ^d,x \\epsilon ℝ^d\n","$\n","\n","\n","$\n","  \\frac{∂b^Tx}{∂x} = \\frac{∂x^Tb}{∂x} = b \n","$\n","  από (69) στο https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf  \n","\n","\n"," $ \\frac{∂x^TAx}{∂x} = (A + A^T)x$\n","   από (81) στο https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf  \n","\n","\n"," Όμως αφού $A^T = A$\n","\n"," $ \\frac{∂x^TAx}{∂x} = 2Ax $\n","\n","  Άρα τελικά\n","  $ ∇f(x) = 2Ax + b$\n","\n"],"metadata":{"id":"mJQYhoPv4FlQ"}},{"cell_type":"markdown","source":["## 2.2"],"metadata":{"id":"4zNnCGfjaPJv"}},{"cell_type":"markdown","source":["#Ερώτημα 3: Gradient descent"],"metadata":{"id":"FMH-rgnz0G5N"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def f1(x1,x2):\n","  return ((x1 - 2)**2 + (x2 - 3)**2)\n","def partialf1x1(x1,x2):\n","  return (2*x1 - 4)\n","\n","def partialf1x2(x1,x2):\n","  return (2*x2 - 6)\n","\n","def f2(x1,x2):\n","  return ((1- (x2 - 3))**2 + 20*((x1 + 3) - (x2 - 3)**2)**2)\n","\n","def partialf2x1(x1,x2):\n","  return (40*(x1 + 3 - (x2 - 3)**2))\n","\n","def partialf2x2(x1,x2):\n","  return (-2*(4-x2) + 40*(x1 + 3 -(x2-3)**2)*(-2*x2 + 6))\n","\n","\n","def gradient_descent(curx1,curx2,rate,maxIter,function,partialx1,partialx2,funName):\n","  actIters = []\n","  precision = 0.0001\n","  result = []\n","  iters = list(range(1,maxIter+1))\n","  print(funName, \": G-D for starting values (%d,%d) learning rate = %.4f and max iterations = %d\"%(curx1,curx2,rate,maxIter))\n","  for iter in range(maxIter):\n","    actIters.append(iter)\n","    prevx1 = curx1\n","    prevx2 = curx2\n","    curx1 = curx1 - (rate * partialx1(curx1,curx2))\n","    curx2 = curx2 - (rate * partialx2(curx1,curx2))\n","    fResult = function(curx1,curx2)\n","    result.append(fResult)\n","    diff1=abs(curx1-prevx1)\n","    diff2=abs(curx2-prevx2)\n","    print(\"Iteration\",iter+1,\":\",funName,\"(x1,x2) =\",fResult)\n","    if (diff1 <= precision and diff2 <= precision):\n","      print(\"The local minimum occurs at (%f,%f) after %d iterations\"%(curx1,curx2,iter+1))\n","      break\n","\n","  #create plot\n","  plt.title(\"rate = %.3f maxIters = %d\"%(rate,maxIter))\n","  plt.xlabel(\"iterations\")\n","  plt.ylabel(\"f1(x1,x2)\")\n","  plt.plot(actIters,result)\n","  plt.show()  \n","  "],"metadata":{"id":"0_9ZUe3i4CS5","executionInfo":{"status":"ok","timestamp":1648716441370,"user_tz":-180,"elapsed":6,"user":{"displayName":"Nick sour","userId":"02771206742206724666"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["gradient_descent(0,0,0.5,10,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"K8bwB6lizXWQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(0,0,0.01,400,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"WhRZbyLeza9p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(0,0,0.1,50,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"SUaHds1qzdDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(0,0,0.4,20,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"Ad-uD_QKze6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(0,0,0.6,20,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"G-kJ3KPrzhOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(0,0,0.7,20,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"Q1nrc5SWzkaI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(0,0,0.9,100,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"ElnBWfQHzm_d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(1,1,0.5,10,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"XK86odVVzqfN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(1,0,0.5,10,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"i6M4_xj2zrEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(1,1,0.4,20,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"vHvs5eh-ztDG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(10,19,0.4,20,f1,partialf1x1,partialf1x2,\"f1\")\n"],"metadata":{"id":"fIpI8IWrzupo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Σχόλια για την f1**\n","\n","1) Για αρχικές τιμές (0,0) και learning rate 0.5 η συνάρτηση βρίσκει κατευθείαν το τοπικό ελάχιστο το οποίο είναι το 0\n","\n","2) Παρατηρούμε ότι για αρχικές τιμές (0,0) και learning rate \"κοντά στο\" 0.5 η σύκλιση επιτυγχάνεται σε λιγότερες επαναλήψεις, ενώ καθως απομακρυνόμαστε από το 0.5 είτε μεγαλώνει το learning rate είτε μικραίνει χρειάζονται όλο και περισσότερες επαναλήψεις.\n","Συγκεκριμένα:\n","\n"," Για learning rate 0.01 318 επαναλήψεις.\n","\n"," Για learning rate0.1 40 επαναλήψεις.\n","\n"," Για learning rate 0.4 8 επαναλήψεις.\n","\n"," Για learning rate 0.6 8 επαναλήψεις.\n","\n"," Για learning rate 0.7 13 επαναλήψεις.\n"," \n"," Για learning rate 0.9 50 επαναλήψεις.\n","\n","3) Για διαφορετικές αρχικές τιμές παρατηρούμε ότι ο αλγόριθμος έχει παρόμοια συμπεριφορά"],"metadata":{"id":"Wa47KcXiXAv4"}},{"cell_type":"code","source":["gradient_descent(0,0,0.001,6000,f2,partialf2x1,partialf2x2,\"f2\")\n"],"metadata":{"id":"aGU85X81y58v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(1,1,0.001,6000,f2,partialf2x1,partialf2x2,\"f2\")\n"],"metadata":{"id":"Kj40F-c0y96l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(2,2,0.001,6000,f2,partialf2x1,partialf2x2,\"f2\")\n"],"metadata":{"id":"tG5h-k_1zBrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(5,5,0.001,6000,f2,partialf2x1,partialf2x2,\"f2\")"],"metadata":{"id":"VRLzvQzhKUBH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gradient_descent(9.01,9.01,0.001,6000,f2,partialf2x1,partialf2x2,\"f2\")"],"metadata":{"id":"svQ-5VwmLZI3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Σχόλια για την f2**\n","\n","1) Για αρχικές τιμές (0,0) και learning rate 0.5 συμβαίνει overflow\n","\n","2) Για την αποφυγή του overflow πρέπει να επιλεγούν μικρές τιμές learning rate\n","\n","3) Για αρχικές τιμές (0,0) και learning rate 0.01 επιτυγχάνεται σύγκλιση ακρίβειας 0.0001 σε 4937 επαναλήψεις \n","\n","4) Όσο μεγαλώνει  η τμή των αρχικών τιμών της συνάρτησης, αυξάνονται οι επαναλήψεις ποθ χρειάζονται για σύγκλιση"],"metadata":{"id":"W5va6b4WbxEA"}}]}